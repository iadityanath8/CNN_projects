{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5174a895-d8db-44a6-9ef2-8ed33ea9a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "889dfa35-06dc-406e-ba48-4d334f7e7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train=True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "425f3c3d-7cd1-4aab-a408-6d374f124eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train=False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e90fc114-2894-42a3-b72f-b2242953725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc4a35da-0715-4a6a-953e-d78768183df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "201abcab-eb43-4c06-a890-81abb2b19d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(\n",
    "        train_data, \n",
    "        batch_size=100,\n",
    "        shuffle=True,\n",
    "        num_workers=1\n",
    "    ),\n",
    "\n",
    "    'test': DataLoader(\n",
    "        test_data, \n",
    "        batch_size=100,\n",
    "        shuffle=True,\n",
    "        num_workers=1\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "053bca69-4c43-4574-9b79-fb2716e70529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69d17b29-2d30-4dcb-8092-0b5a925f8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv_dropout = nn.Dropout2d()\n",
    "        self.fcl1 = nn.Linear(320, 50)\n",
    "        self.fcl2 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv_dropout(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fcl1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fcl2(x)\n",
    "        return F.softmax(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7305dc7-9663-4c3a-964a-7d030980de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()    # backpropogate \n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 30 == 0:\n",
    "            print(f\"Training Epoch {epoch}, [{batch_idx*len(data)}], loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(loaders['test'].dataset)\n",
    "        print(f\"loss: {test_loss:.4f}, accuracy: {correct / len(loaders['test'].dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b0d9fb2-188c-4cfa-85ea-c2938e9010d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6954/3403551844.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1, [0], loss: 2.3031809329986572\n",
      "Training Epoch 1, [3000], loss: 2.273954391479492\n",
      "Training Epoch 1, [6000], loss: 2.086544990539551\n",
      "Training Epoch 1, [9000], loss: 1.983683466911316\n",
      "Training Epoch 1, [12000], loss: 1.8659390211105347\n",
      "Training Epoch 1, [15000], loss: 1.736417293548584\n",
      "Training Epoch 1, [18000], loss: 1.7683725357055664\n",
      "Training Epoch 1, [21000], loss: 1.7813929319381714\n",
      "Training Epoch 1, [24000], loss: 1.766577124595642\n",
      "Training Epoch 1, [27000], loss: 1.6924138069152832\n",
      "Training Epoch 1, [30000], loss: 1.6788954734802246\n",
      "Training Epoch 1, [33000], loss: 1.6786775588989258\n",
      "Training Epoch 1, [36000], loss: 1.579246997833252\n",
      "Training Epoch 1, [39000], loss: 1.6465226411819458\n",
      "Training Epoch 1, [42000], loss: 1.6050480604171753\n",
      "Training Epoch 1, [45000], loss: 1.6020535230636597\n",
      "Training Epoch 1, [48000], loss: 1.6059969663619995\n",
      "Training Epoch 1, [51000], loss: 1.7357254028320312\n",
      "Training Epoch 1, [54000], loss: 1.6195825338363647\n",
      "Training Epoch 1, [57000], loss: 1.5946297645568848\n",
      "loss: 0.0153, accuracy: 0.9328\n",
      "Training Epoch 2, [0], loss: 1.6459158658981323\n",
      "Training Epoch 2, [3000], loss: 1.688565969467163\n",
      "Training Epoch 2, [6000], loss: 1.6025198698043823\n",
      "Training Epoch 2, [9000], loss: 1.5826096534729004\n",
      "Training Epoch 2, [12000], loss: 1.575520634651184\n",
      "Training Epoch 2, [15000], loss: 1.6527987718582153\n",
      "Training Epoch 2, [18000], loss: 1.6015880107879639\n",
      "Training Epoch 2, [21000], loss: 1.571342945098877\n",
      "Training Epoch 2, [24000], loss: 1.5972814559936523\n",
      "Training Epoch 2, [27000], loss: 1.5616559982299805\n",
      "Training Epoch 2, [30000], loss: 1.5549108982086182\n",
      "Training Epoch 2, [33000], loss: 1.5494827032089233\n",
      "Training Epoch 2, [36000], loss: 1.6306633949279785\n",
      "Training Epoch 2, [39000], loss: 1.5535086393356323\n",
      "Training Epoch 2, [42000], loss: 1.5606951713562012\n",
      "Training Epoch 2, [45000], loss: 1.5809065103530884\n",
      "Training Epoch 2, [48000], loss: 1.556435227394104\n",
      "Training Epoch 2, [51000], loss: 1.5726650953292847\n",
      "Training Epoch 2, [54000], loss: 1.5985876321792603\n",
      "Training Epoch 2, [57000], loss: 1.5551941394805908\n",
      "loss: 0.0151, accuracy: 0.952\n",
      "Training Epoch 3, [0], loss: 1.5571461915969849\n",
      "Training Epoch 3, [3000], loss: 1.5629370212554932\n",
      "Training Epoch 3, [6000], loss: 1.5329443216323853\n",
      "Training Epoch 3, [9000], loss: 1.5575506687164307\n",
      "Training Epoch 3, [12000], loss: 1.5992072820663452\n",
      "Training Epoch 3, [15000], loss: 1.5397952795028687\n",
      "Training Epoch 3, [18000], loss: 1.595605731010437\n",
      "Training Epoch 3, [21000], loss: 1.5211842060089111\n",
      "Training Epoch 3, [24000], loss: 1.5759880542755127\n",
      "Training Epoch 3, [27000], loss: 1.5701419115066528\n",
      "Training Epoch 3, [30000], loss: 1.5300467014312744\n",
      "Training Epoch 3, [33000], loss: 1.5784693956375122\n",
      "Training Epoch 3, [36000], loss: 1.5763005018234253\n",
      "Training Epoch 3, [39000], loss: 1.565494418144226\n",
      "Training Epoch 3, [42000], loss: 1.5214450359344482\n",
      "Training Epoch 3, [45000], loss: 1.5648456811904907\n",
      "Training Epoch 3, [48000], loss: 1.570286512374878\n",
      "Training Epoch 3, [51000], loss: 1.5621780157089233\n",
      "Training Epoch 3, [54000], loss: 1.549143671989441\n",
      "Training Epoch 3, [57000], loss: 1.5583816766738892\n",
      "loss: 0.0151, accuracy: 0.9563\n",
      "Training Epoch 4, [0], loss: 1.6029787063598633\n",
      "Training Epoch 4, [3000], loss: 1.5046703815460205\n",
      "Training Epoch 4, [6000], loss: 1.5633920431137085\n",
      "Training Epoch 4, [9000], loss: 1.5858492851257324\n",
      "Training Epoch 4, [12000], loss: 1.5743904113769531\n",
      "Training Epoch 4, [15000], loss: 1.5217046737670898\n",
      "Training Epoch 4, [18000], loss: 1.5329766273498535\n",
      "Training Epoch 4, [21000], loss: 1.5832237005233765\n",
      "Training Epoch 4, [24000], loss: 1.5421980619430542\n",
      "Training Epoch 4, [27000], loss: 1.5487163066864014\n",
      "Training Epoch 4, [30000], loss: 1.555488109588623\n",
      "Training Epoch 4, [33000], loss: 1.5661550760269165\n",
      "Training Epoch 4, [36000], loss: 1.5390440225601196\n",
      "Training Epoch 4, [39000], loss: 1.53007173538208\n",
      "Training Epoch 4, [42000], loss: 1.5362298488616943\n",
      "Training Epoch 4, [45000], loss: 1.5391675233840942\n",
      "Training Epoch 4, [48000], loss: 1.5035147666931152\n",
      "Training Epoch 4, [51000], loss: 1.562522530555725\n",
      "Training Epoch 4, [54000], loss: 1.5311557054519653\n",
      "Training Epoch 4, [57000], loss: 1.5621424913406372\n",
      "loss: 0.0150, accuracy: 0.9642\n",
      "Training Epoch 5, [0], loss: 1.5203437805175781\n",
      "Training Epoch 5, [3000], loss: 1.540989875793457\n",
      "Training Epoch 5, [6000], loss: 1.5112701654434204\n",
      "Training Epoch 5, [9000], loss: 1.5077834129333496\n",
      "Training Epoch 5, [12000], loss: 1.5758445262908936\n",
      "Training Epoch 5, [15000], loss: 1.5810214281082153\n",
      "Training Epoch 5, [18000], loss: 1.5574008226394653\n",
      "Training Epoch 5, [21000], loss: 1.5499162673950195\n",
      "Training Epoch 5, [24000], loss: 1.5894969701766968\n",
      "Training Epoch 5, [27000], loss: 1.5594967603683472\n",
      "Training Epoch 5, [30000], loss: 1.5863336324691772\n",
      "Training Epoch 5, [33000], loss: 1.5176613330841064\n",
      "Training Epoch 5, [36000], loss: 1.560398817062378\n",
      "Training Epoch 5, [39000], loss: 1.5191891193389893\n",
      "Training Epoch 5, [42000], loss: 1.522892713546753\n",
      "Training Epoch 5, [45000], loss: 1.5878584384918213\n",
      "Training Epoch 5, [48000], loss: 1.5147027969360352\n",
      "Training Epoch 5, [51000], loss: 1.562950849533081\n",
      "Training Epoch 5, [54000], loss: 1.5400501489639282\n",
      "Training Epoch 5, [57000], loss: 1.5338267087936401\n",
      "loss: 0.0149, accuracy: 0.967\n",
      "Training Epoch 6, [0], loss: 1.4934577941894531\n",
      "Training Epoch 6, [3000], loss: 1.4877536296844482\n",
      "Training Epoch 6, [6000], loss: 1.5495373010635376\n",
      "Training Epoch 6, [9000], loss: 1.5815354585647583\n",
      "Training Epoch 6, [12000], loss: 1.530564308166504\n",
      "Training Epoch 6, [15000], loss: 1.5707757472991943\n",
      "Training Epoch 6, [18000], loss: 1.5273594856262207\n",
      "Training Epoch 6, [21000], loss: 1.5297006368637085\n",
      "Training Epoch 6, [24000], loss: 1.548557162284851\n",
      "Training Epoch 6, [27000], loss: 1.5305372476577759\n",
      "Training Epoch 6, [30000], loss: 1.561741828918457\n",
      "Training Epoch 6, [33000], loss: 1.5342450141906738\n",
      "Training Epoch 6, [36000], loss: 1.520432949066162\n",
      "Training Epoch 6, [39000], loss: 1.5185627937316895\n",
      "Training Epoch 6, [42000], loss: 1.5335545539855957\n",
      "Training Epoch 6, [45000], loss: 1.5444825887680054\n",
      "Training Epoch 6, [48000], loss: 1.5250622034072876\n",
      "Training Epoch 6, [51000], loss: 1.558294415473938\n",
      "Training Epoch 6, [54000], loss: 1.546883225440979\n",
      "Training Epoch 6, [57000], loss: 1.5388760566711426\n",
      "loss: 0.0149, accuracy: 0.9691\n",
      "Training Epoch 7, [0], loss: 1.585496187210083\n",
      "Training Epoch 7, [3000], loss: 1.5267258882522583\n",
      "Training Epoch 7, [6000], loss: 1.5759682655334473\n",
      "Training Epoch 7, [9000], loss: 1.5494564771652222\n",
      "Training Epoch 7, [12000], loss: 1.5005220174789429\n",
      "Training Epoch 7, [15000], loss: 1.5336326360702515\n",
      "Training Epoch 7, [18000], loss: 1.5372304916381836\n",
      "Training Epoch 7, [21000], loss: 1.5252788066864014\n",
      "Training Epoch 7, [24000], loss: 1.5297530889511108\n",
      "Training Epoch 7, [27000], loss: 1.5445582866668701\n",
      "Training Epoch 7, [30000], loss: 1.5498855113983154\n",
      "Training Epoch 7, [33000], loss: 1.529533863067627\n",
      "Training Epoch 7, [36000], loss: 1.5363637208938599\n",
      "Training Epoch 7, [39000], loss: 1.5422443151474\n",
      "Training Epoch 7, [42000], loss: 1.5024158954620361\n",
      "Training Epoch 7, [45000], loss: 1.5447016954421997\n",
      "Training Epoch 7, [48000], loss: 1.5354084968566895\n",
      "Training Epoch 7, [51000], loss: 1.5807101726531982\n",
      "Training Epoch 7, [54000], loss: 1.5196536779403687\n",
      "Training Epoch 7, [57000], loss: 1.5055540800094604\n",
      "loss: 0.0149, accuracy: 0.9703\n",
      "Training Epoch 8, [0], loss: 1.5755611658096313\n",
      "Training Epoch 8, [3000], loss: 1.5597152709960938\n",
      "Training Epoch 8, [6000], loss: 1.522287130355835\n",
      "Training Epoch 8, [9000], loss: 1.5368201732635498\n",
      "Training Epoch 8, [12000], loss: 1.5697808265686035\n",
      "Training Epoch 8, [15000], loss: 1.5815761089324951\n",
      "Training Epoch 8, [18000], loss: 1.5526034832000732\n",
      "Training Epoch 8, [21000], loss: 1.537135124206543\n",
      "Training Epoch 8, [24000], loss: 1.530511498451233\n",
      "Training Epoch 8, [27000], loss: 1.5380864143371582\n",
      "Training Epoch 8, [30000], loss: 1.571372389793396\n",
      "Training Epoch 8, [33000], loss: 1.498984694480896\n",
      "Training Epoch 8, [36000], loss: 1.529097318649292\n",
      "Training Epoch 8, [39000], loss: 1.5168335437774658\n",
      "Training Epoch 8, [42000], loss: 1.521192193031311\n",
      "Training Epoch 8, [45000], loss: 1.4754152297973633\n",
      "Training Epoch 8, [48000], loss: 1.5886509418487549\n",
      "Training Epoch 8, [51000], loss: 1.497624397277832\n",
      "Training Epoch 8, [54000], loss: 1.5380500555038452\n",
      "Training Epoch 8, [57000], loss: 1.5037970542907715\n",
      "loss: 0.0149, accuracy: 0.9713\n",
      "Training Epoch 9, [0], loss: 1.535862684249878\n",
      "Training Epoch 9, [3000], loss: 1.5584927797317505\n",
      "Training Epoch 9, [6000], loss: 1.4959344863891602\n",
      "Training Epoch 9, [9000], loss: 1.5007182359695435\n",
      "Training Epoch 9, [12000], loss: 1.5269240140914917\n",
      "Training Epoch 9, [15000], loss: 1.506568193435669\n",
      "Training Epoch 9, [18000], loss: 1.5156179666519165\n",
      "Training Epoch 9, [21000], loss: 1.5123732089996338\n",
      "Training Epoch 9, [24000], loss: 1.4882197380065918\n",
      "Training Epoch 9, [27000], loss: 1.560701847076416\n",
      "Training Epoch 9, [30000], loss: 1.5319877862930298\n",
      "Training Epoch 9, [33000], loss: 1.5336670875549316\n",
      "Training Epoch 9, [36000], loss: 1.5450010299682617\n",
      "Training Epoch 9, [39000], loss: 1.5292580127716064\n",
      "Training Epoch 9, [42000], loss: 1.5567556619644165\n",
      "Training Epoch 9, [45000], loss: 1.5341432094573975\n",
      "Training Epoch 9, [48000], loss: 1.5500706434249878\n",
      "Training Epoch 9, [51000], loss: 1.5533491373062134\n",
      "Training Epoch 9, [54000], loss: 1.5439212322235107\n",
      "Training Epoch 9, [57000], loss: 1.5206910371780396\n",
      "loss: 0.0149, accuracy: 0.9738\n",
      "Training Epoch 10, [0], loss: 1.5516433715820312\n",
      "Training Epoch 10, [3000], loss: 1.5393043756484985\n",
      "Training Epoch 10, [6000], loss: 1.5104347467422485\n",
      "Training Epoch 10, [9000], loss: 1.51267671585083\n",
      "Training Epoch 10, [12000], loss: 1.5005301237106323\n",
      "Training Epoch 10, [15000], loss: 1.492485761642456\n",
      "Training Epoch 10, [18000], loss: 1.5351662635803223\n",
      "Training Epoch 10, [21000], loss: 1.5086079835891724\n",
      "Training Epoch 10, [24000], loss: 1.5032305717468262\n",
      "Training Epoch 10, [27000], loss: 1.5434261560440063\n",
      "Training Epoch 10, [30000], loss: 1.5532925128936768\n",
      "Training Epoch 10, [33000], loss: 1.5371108055114746\n",
      "Training Epoch 10, [36000], loss: 1.531019926071167\n",
      "Training Epoch 10, [39000], loss: 1.5430411100387573\n",
      "Training Epoch 10, [42000], loss: 1.5284708738327026\n",
      "Training Epoch 10, [45000], loss: 1.5309444665908813\n",
      "Training Epoch 10, [48000], loss: 1.5474934577941895\n",
      "Training Epoch 10, [51000], loss: 1.580732822418213\n",
      "Training Epoch 10, [54000], loss: 1.5303175449371338\n",
      "Training Epoch 10, [57000], loss: 1.5590507984161377\n",
      "loss: 0.0149, accuracy: 0.9746\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "45447bdd-bd15-4a60-b438-0aca1588b192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6954/3403551844.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[1010]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data.to(device))\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True)\n",
    "print(f\"prediction {prediction.item()}\")\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
